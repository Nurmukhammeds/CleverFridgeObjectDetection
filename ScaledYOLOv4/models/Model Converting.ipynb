{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fd7998",
   "metadata": {},
   "source": [
    "## Pytorch to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1967e3ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15731/2267160350.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from models.common import *\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg='yolov4-p5.yaml', ch=3, nc=None):  # model, input channels, number of classes\n",
    "        super(Model, self).__init__()\n",
    "        if isinstance(cfg, dict):\n",
    "            self.yaml = cfg  # model dict\n",
    "        else:  # is *.yaml\n",
    "            import yaml  # for torch hub\n",
    "            self.yaml_file = Path(cfg).name\n",
    "            with open(cfg) as f:\n",
    "                self.yaml = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n",
    "\n",
    "        # Define model\n",
    "        if nc and nc != self.yaml['nc']:\n",
    "            print('Overriding %s nc=%g with nc=%g' % (cfg, self.yaml['nc'], nc))\n",
    "            self.yaml['nc'] = nc  # override yaml value\n",
    "        self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])  # model, savelist, ch_out\n",
    "        # print([x.shape for x in self.forward(torch.zeros(1, ch, 64, 64))])\n",
    "\n",
    "        # Build strides, anchors\n",
    "        m = self.model[-1]  # Detect()\n",
    "        if isinstance(m, Detect):\n",
    "            s = 256  # 2x min stride\n",
    "            m.stride = torch.tensor([s / x.shape[-2] for x in self.forward(torch.zeros(1, ch, s, s))])  # forward\n",
    "            m.anchors /= m.stride.view(-1, 1, 1)\n",
    "            check_anchor_order(m)\n",
    "            self.stride = m.stride\n",
    "            self._initialize_biases()  # only run once\n",
    "            # print('Strides: %s' % m.stride.tolist())\n",
    "\n",
    "        # Init weights, biases\n",
    "        initialize_weights(self)\n",
    "        self.info()\n",
    "        print('')\n",
    "\n",
    "    def forward(self, x, augment=False, profile=False):\n",
    "        if augment:\n",
    "            img_size = x.shape[-2:]  # height, width\n",
    "            s = [1, 0.83, 0.67]  # scales\n",
    "            f = [None, 3, None]  # flips (2-ud, 3-lr)\n",
    "            y = []  # outputs\n",
    "            for si, fi in zip(s, f):\n",
    "                xi = scale_img(x.flip(fi) if fi else x, si)\n",
    "                yi = self.forward_once(xi)[0]  # forward\n",
    "                # cv2.imwrite('img%g.jpg' % s, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])  # save\n",
    "                yi[..., :4] /= si  # de-scale\n",
    "                if fi == 2:\n",
    "                    yi[..., 1] = img_size[0] - yi[..., 1]  # de-flip ud\n",
    "                elif fi == 3:\n",
    "                    yi[..., 0] = img_size[1] - yi[..., 0]  # de-flip lr\n",
    "                y.append(yi)\n",
    "            return torch.cat(y, 1), None  # augmented inference, train\n",
    "        else:\n",
    "            return self.forward_once(x, profile)  # single-scale inference, train\n",
    "\n",
    "    def forward_once(self, x, profile=False):\n",
    "        y, dt = [], []  # outputs\n",
    "        for m in self.model:\n",
    "            if m.f != -1:  # if not from previous layer\n",
    "                x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
    "\n",
    "            if profile:\n",
    "                try:\n",
    "                    import thop\n",
    "                    o = thop.profile(m, inputs=(x,), verbose=False)[0] / 1E9 * 2  # FLOPS\n",
    "                except:\n",
    "                    o = 0\n",
    "                t = time_synchronized()\n",
    "                for _ in range(10):\n",
    "                    _ = m(x)\n",
    "                dt.append((time_synchronized() - t) * 100)\n",
    "                print('%10.1f%10.0f%10.1fms %-40s' % (o, m.np, dt[-1], m.type))\n",
    "\n",
    "            x = m(x)  # run\n",
    "            y.append(x if m.i in self.save else None)  # save output\n",
    "\n",
    "        if profile:\n",
    "            print('%.1fms total' % sum(dt))\n",
    "        return x\n",
    "\n",
    "    def _initialize_biases(self, cf=None):  # initialize biases into Detect(), cf is class frequency\n",
    "        # cf = torch.bincount(torch.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1.\n",
    "        m = self.model[-1]  # Detect() module\n",
    "        for mi, s in zip(m.m, m.stride):  # from\n",
    "            b = mi.bias.view(m.na, -1)  # conv.bias(255) to (3,85)\n",
    "            b[:, 4].data += math.log(8 / (640 / s) ** 2)  # obj (8 objects per 640 image)\n",
    "            b[:, 5:].data += math.log(0.6 / (m.nc - 0.99)) if cf is None else torch.log(cf / cf.sum())  # cls\n",
    "            mi.bias = torch.nn.Parameter(b.view(-1), requires_grad=True)\n",
    "\n",
    "    def _print_biases(self):\n",
    "        m = self.model[-1]  # Detect() module\n",
    "        for mi in m.m:  # from\n",
    "            b = mi.bias.detach().view(m.na, -1).T  # conv.bias(255) to (3,85)\n",
    "            print(('%6g Conv2d.bias:' + '%10.3g' * 6) % (mi.weight.shape[1], *b[:5].mean(1).tolist(), b[5:].mean()))\n",
    "\n",
    "    # def _print_weights(self):\n",
    "    #     for m in self.model.modules():\n",
    "    #         if type(m) is Bottleneck:\n",
    "    #             print('%10.3g' % (m.w.detach().sigmoid() * 2))  # shortcut weights\n",
    "\n",
    "    def fuse(self):  # fuse model Conv2d() + BatchNorm2d() layers\n",
    "        print('Fusing layers... ', end='')\n",
    "        for m in self.model.modules():\n",
    "            if type(m) is Conv:\n",
    "                m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatability\n",
    "                m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv\n",
    "                m.bn = None  # remove batchnorm\n",
    "                m.forward = m.fuseforward  # update forward\n",
    "        self.info()\n",
    "        return self\n",
    "\n",
    "    def info(self):  # print model information\n",
    "        model_info(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f25b81d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15731/3264076246.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'yolov4-csp.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15731/3544609860.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, ch, nc)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Overriding %s nc=%g with nc=%g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m  \u001b[0;31m# override yaml value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model, savelist, ch_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print([x.shape for x in self.forward(torch.zeros(1, ch, 64, 64))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model(cfg='yolov4-csp.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd7210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
